"""
Bloomberg pull for gilt-open inputs (robust to pdblp variations)

Fixes:
- Use eventType= for bdib (fallback to positional if needed)
- Safe BDH wrapper (no crash on entitlement/ticker/field issues)
- Gilt daily: try PX_OPEN, fallback to PX_LAST
- Clear messages if any dataset is empty
"""

import pandas as pd
import numpy as np
import pdblp
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import pytz
import sys

# --------- CONFIG ---------
LONDON_TZ = pytz.timezone("Europe/London")

# Verify tickers on your terminal (change if your desk uses different chains)
TICKERS = {
    "gilt_future": "G 1 Comdty",    # 10y gilt (continuous 1st) — confirm
    "bund_future": "RX1 Comdty",    # Euro-Bund (continuous 1st)
    "ust_future":  "TY1 Comdty",    # US 10y Treasury (continuous 1st)
    "gbpusd_spot": "GBPUSD Curncy", # GBPUSD spot
    "vix_index":   "VIX Index",     # CBOE VIX
}

# 5-minute “pre-open” window (London time)
PREOPEN_START = (7, 0)
PREOPEN_END   = (8, 0)
BAR_INTERVAL_MIN = 5

INTRADAY_LOOKBACK_DAYS = 90
DAILY_LOOKBACK_MONTHS  = 3
OUT_XLSX = "bbg_gilt_inputs.xlsx"
# --------------------------


def business_days_london(start_date, end_date):
    """Weekdays only (plug a holiday calendar if needed)."""
    return pd.date_range(start=start_date, end=end_date, freq="B", tz=LONDON_TZ)


def safe_bdh(con, tickers, fields, start_date, end_date):
    """
    Safe wrapper over con.bdh -> tidy long [date, ticker, field, value].
    Returns empty DF on any error and prints a clear message.
    """
    if isinstance(tickers, str): tickers = [tickers]
    if isinstance(fields, str):  fields  = [fields]
    if not tickers or not fields:
        print("⚠️  safe_bdh: empty tickers/fields")
        return pd.DataFrame(columns=["date", "ticker", "field", "value"])
    try:
        df = con.bdh(tickers, fields, start_date, end_date)
        if df is None or df.empty:
            print(f"⚠️  safe_bdh: no data for tickers={tickers} fields={fields}")
            return pd.DataFrame(columns=["date", "ticker", "field", "value"])
        df = df.stack(level=0).reset_index()
        df.columns = ["date", "field", "ticker", "value"]
        return df
    except Exception as e:
        print(f"❌ safe_bdh error for tickers={tickers} fields={fields}: {e}")
        return pd.DataFrame(columns=["date", "ticker", "field", "value"])


def get_intraday_first_last(con, ticker, dates, start_hm, end_hm, interval):
    """
    For each tz-aware London date, pull 5m bars in [start_hm, end_hm).
    Uses eventType='TRADE' (fallback to positional if the kw isn’t supported).
    Returns DataFrame: date, first, last, delta.
    """
    rows = []
    for d in dates:
        d_loc = d.astimezone(LONDON_TZ)
        start_dt = d_loc.replace(hour=start_hm[0], minute=start_hm[1], second=0, microsecond=0)
        end_dt   = d_loc.replace(hour=end_hm[0],   minute=end_hm[1],   second=0, microsecond=0)

        start_naive = start_dt.replace(tzinfo=None)
        end_naive   = end_dt.replace(tzinfo=None)

        try:
            # Newer pdblp accepts event=; older uses eventType or positional.
            try:
                bars = con.bdib(ticker, start_naive, end_naive, eventType="TRADE", interval=interval)
            except TypeError:
                # Fallback: positional order (security, start, end, eventType, interval)
                bars = con.bdib(ticker, start_naive, end_naive, "TRADE", interval)
        except Exception as e:
            print(f"❌ bdib error for {ticker} on {d_loc.date()}: {e}")
            continue

        if bars is None or bars.empty:
            continue

        bars = bars.sort_values("time")
        first_px = float(bars["close"].iloc[0])
        last_px  = float(bars["close"].iloc[-1])
        rows.append({
            "date": d_loc.date(),
            "first": first_px,
            "last": last_px,
            "delta": last_px - first_px
        })

    return pd.DataFrame(rows)


def fetch_all():
    con = pdblp.BCon(host="localhost", port=8194, timeout=5000)
    con.start()

    today_loc = datetime.now(tz=LONDON_TZ).date()
    intraday_start = today_loc - timedelta(days=INTRADAY_LOOKBACK_DAYS)
    daily_start = (datetime.now(tz=LONDON_TZ) - relativedelta(months=DAILY_LOOKBACK_MONTHS)).date()

    days = business_days_london(intraday_start, today_loc)

    print("Pulling intraday 5m bars (07:00–08:00 London)...")
    bund = get_intraday_first_last(con, TICKERS["bund_future"], days, PREOPEN_START, PREOPEN_END, BAR_INTERVAL_MIN)
    ust  = get_intraday_first_last(con, TICKERS["ust_future"],  days, PREOPEN_START, PREOPEN_END, BAR_INTERVAL_MIN)
    gbp  = get_intraday_first_last(con, TICKERS["gbpusd_spot"], days, PREOPEN_START, PREOPEN_END, BAR_INTERVAL_MIN)

    bund = bund.rename(columns={"first":"bund_first","last":"bund_last","delta":"bund_delta"})
    ust  = ust.rename(columns={"first":"ust_first","last":"ust_last","delta":"ust_delta"})
    gbp  = gbp.rename(columns={"first":"gbp_first","last":"gbp_last","delta":"gbp_delta"})

    print("Pulling daily VIX and gilt (PX_OPEN -> fallback PX_LAST)...")
    bdh_vix  = safe_bdh(con, TICKERS["vix_index"],   "PX_LAST", daily_start, today_loc)
    # Try PX_OPEN for gilt first
    bdh_gilt = safe_bdh(con, TICKERS["gilt_future"], "PX_OPEN", daily_start, today_loc)
    if bdh_gilt.empty:
        print("⚠️  Gilt PX_OPEN unavailable; falling back to PX_LAST")
        bdh_gilt = safe_bdh(con, TICKERS["gilt_future"], "PX_LAST", daily_start, today_loc)

    vix  = bdh_vix.loc[bdh_vix["field"] == "PX_LAST", ["date", "value"]].rename(columns={"value":"VIX"})
    gilt = bdh_gilt.loc[:, ["date", "value"]].rename(columns={"value":"gilt_open"})  # open or last, labeled as open

    # Early warnings if any piece is empty
    for name, df in [("bund", bund), ("ust", ust), ("gbp", gbp), ("vix", vix), ("gilt", gilt)]:
        if df.empty:
            print(f"⚠️  Warning: {name} dataset is empty. Check entitlements/tickers/time window.")

    # Merge (guard against empties)
    if gilt.empty:
        print("❌ Cannot build daily table without gilt series. Aborting merge.")
        daily = pd.DataFrame()
    else:
        daily = gilt.copy()
        for part, cols in [(bund, ["bund_first","bund_last","bund_delta"]),
                           (ust,  ["ust_first","ust_last","ust_delta"]),
                           (gbp,  ["gbp_first","gbp_last","gbp_delta"]),
                           (vix,  ["VIX"])]:
            if not part.empty:
                daily = daily.merge(part, on="date", how="left")
        daily = daily.dropna().sort_values("date").reset_index(drop=True)

    con.stop()
    return {"bund": bund, "ust": ust, "gbp": gbp, "vix": vix, "gilt": gilt, "daily": daily}


def main():
    data = fetch_all()

    # Previews
    for k in ["bund","ust","gbp","vix","gilt","daily"]:
        print(f"\n=== {k.upper()} ===")
        print(data[k].tail(5))

    # Save to Excel
    with pd.ExcelWriter(OUT_XLSX, engine="xlsxwriter") as xw:
        for key, df in data.items():
            df.to_excel(xw, sheet_name=key[:31], index=False)

    print(f"\nSaved all datasets to: {OUT_XLSX}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n❌ Script failed: {e}")
        sys.exit(1)
