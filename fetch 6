"""
Bloomberg pull for gilt-open inputs (with GT10 Govt as UST yield)

- Intraday 5m (07:00–08:00 London): RX1, GBPUSD
- Daily: GT10 Govt (PX_LAST), VIX Index (PX_LAST), Gilt (PX_OPEN→PX_LAST)
- Saves results to bbg_gilt_inputs.xlsx
"""

import pandas as pd
import numpy as np
import pdblp
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import pytz
import sys

# --------- CONFIG ---------
LONDON_TZ = pytz.timezone("Europe/London")

TICKERS = {
    "gilt_future":  "G 1 Comdty",     # adjust if your desk uses another gilt chain
    "bund_future":  "RX1 Comdty",
    "ust_yield":    "GT10 Govt",      # U.S. 10Y benchmark yield
    "gbpusd_spot":  "GBPUSD Curncy",
    "vix_index":    "VIX Index",
}

PREOPEN_START = (7, 0)
PREOPEN_END   = (8, 0)
BAR_INTERVAL_MIN = 5

INTRADAY_LOOKBACK_DAYS = 90
DAILY_LOOKBACK_MONTHS  = 3
OUT_XLSX = "bbg_gilt_inputs.xlsx"
# --------------------------


def business_days_london(start_date, end_date):
    return pd.date_range(start=start_date, end=end_date, freq="B", tz=LONDON_TZ)


def safe_bdh(con, tickers, fields, start_date, end_date):
    """
    Safe bdh → tidy [date, ticker, field, value]; empty DF on error.

    pdblp.bdh typically returns a DataFrame with a MultiIndex on columns:
    - level 0: ticker
    - level 1: field
    We stack both levels so we always get a long format.
    """
    if isinstance(tickers, str):
        tickers = [tickers]
    if isinstance(fields, str):
        fields = [fields]

    try:
        df = con.bdh(tickers, fields, start_date, end_date)

        if df is None or df.empty:
            print(f"⚠️  safe_bdh: no data for tickers={tickers} fields={fields}")
            return pd.DataFrame(columns=["date", "ticker", "field", "value"])

        # MultiIndex columns (common pdblp case): (ticker, field)
        if isinstance(df.columns, pd.MultiIndex):
            # stack all column levels -> index (date, ticker, field)
            df_long = df.stack(list(range(df.columns.nlevels))).reset_index()
            # After reset_index: columns are [date, level_1, level_2, 0]
            df_long.columns = ["date", "ticker", "field", "value"]

        else:
            # Fallback: single-level columns (e.g. single ticker/field)
            df = df.copy()
            if df.index.name is None:
                df.index.name = "date"
            df_long = df.reset_index().melt(
                id_vars="date",
                var_name="ticker",
                value_name="value",
            )
            # If multiple fields were requested, this fallback won't preserve them;
            # but for current use we only ever request a single field at a time.
            df_long["field"] = fields[0]
            df_long = df_long[["date", "ticker", "field", "value"]]

        return df_long

    except Exception as e:
        print(f"❌ safe_bdh error for tickers={tickers} fields={fields}: {e}")
        return pd.DataFrame(columns=["date", "ticker", "field", "value"])


def normalize_bdib(bars: pd.DataFrame) -> pd.DataFrame:
    """Normalize bdib output across pdblp versions."""
    if bars is None or bars.empty:
        return pd.DataFrame()
    if isinstance(bars.index, pd.DatetimeIndex) and "time" not in bars.columns:
        bars = bars.reset_index()
    bars.columns = [str(c).lower() for c in bars.columns]
    if "time" not in bars.columns and "datetime" in bars.columns:
        bars = bars.rename(columns={"datetime": "time"})
    if "close" not in bars.columns and "price" in bars.columns:
        bars = bars.rename(columns={"price": "close"})
    if "close" not in bars.columns:
        raise ValueError("bdib: no close column found")
    if "time" not in bars.columns:
        raise ValueError("bdib: no time column found")
    return bars[["time", "close"]]


def get_intraday_first_last(con, ticker, dates, start_hm, end_hm, interval):
    """Pull 5m intraday bars (07:00–08:00) and compute first/last/delta."""
    rows = []
    for d in dates:
        d_loc = d.astimezone(LONDON_TZ)
        start_dt = d_loc.replace(hour=start_hm[0], minute=start_hm[1])
        end_dt   = d_loc.replace(hour=end_hm[0],   minute=end_hm[1])
        start_naive = start_dt.replace(tzinfo=None)
        end_naive   = end_dt.replace(tzinfo=None)

        try:
            try:
                bars = con.bdib(
                    ticker,
                    start_naive,
                    end_naive,
                    eventType="TRADE",
                    interval=interval,
                )
            except TypeError:
                bars = con.bdib(
                    ticker,
                    start_naive,
                    end_naive,
                    "TRADE",
                    interval,
                )
            bars = normalize_bdib(bars)
        except Exception as e:
            print(f"❌ bdib error for {ticker} on {d_loc.date()}: {e}")
            continue

        if bars.empty:
            continue

        bars = bars.sort_values("time")
        first_px = float(bars["close"].iloc[0])
        last_px  = float(bars["close"].iloc[-1])
        rows.append(
            {
                "date": d_loc.date(),
                "first": first_px,
                "last":  last_px,
                "delta": last_px - first_px,
            }
        )

    return pd.DataFrame(rows)


def fetch_all():
    con = pdblp.BCon(host="localhost", port=8194, timeout=5000)
    con.start()

    today_loc = datetime.now(tz=LONDON_TZ).date()
    intraday_start = today_loc - timedelta(days=INTRADAY_LOOKBACK_DAYS)
    daily_start = (datetime.now(tz=LONDON_TZ) - relativedelta(months=DAILY_LOOKBACK_MONTHS)).date()
    days = business_days_london(intraday_start, today_loc)

    print("Pulling intraday Bund & GBPUSD (07:00–08:00 London)...")
    bund = get_intraday_first_last(
        con,
        TICKERS["bund_future"],
        days,
        PREOPEN_START,
        PREOPEN_END,
        BAR_INTERVAL_MIN,
    )
    gbp  = get_intraday_first_last(
        con,
        TICKERS["gbpusd_spot"],
        days,
        PREOPEN_START,
        PREOPEN_END,
        BAR_INTERVAL_MIN,
    )

    bund = bund.rename(
        columns={
            "first": "bund_first",
            "last":  "bund_last",
            "delta": "bund_delta",
        }
    )
    gbp  = gbp.rename(
        columns={
            "first": "gbp_first",
            "last":  "gbp_last",
            "delta": "gbp_delta",
        }
    )

    print("Pulling daily GT10 Govt (UST yield), VIX, and Gilt...")
    ust_bdh  = safe_bdh(con, TICKERS["ust_yield"],   "PX_LAST", daily_start, today_loc)
    vix_bdh  = safe_bdh(con, TICKERS["vix_index"],   "PX_LAST", daily_start, today_loc)
    gilt_bdh = safe_bdh(con, TICKERS["gilt_future"], "PX_OPEN", daily_start, today_loc)

    if gilt_bdh.empty:
        print("⚠️  Gilt PX_OPEN unavailable; falling back to PX_LAST")
        gilt_bdh = safe_bdh(con, TICKERS["gilt_future"], "PX_LAST", daily_start, today_loc)

    ust  = ust_bdh.loc[ust_bdh["field"] == "PX_LAST", ["date", "value"]].rename(
        columns={"value": "ust_yield"}
    )
    vix  = vix_bdh.loc[vix_bdh["field"] == "PX_LAST", ["date", "value"]].rename(
        columns={"value": "VIX"}
    )
    # gilt_bdh will have a single field (PX_OPEN or PX_LAST), so no need to filter by field
    gilt = gilt_bdh.loc[:, ["date", "value"]].rename(columns={"value": "gilt_open"})

    con.stop()

    return {
        "bund": bund,
        "gbp":  gbp,
        "ust":  ust,
        "vix":  vix,
        "gilt": gilt,
    }


def main():
    data = fetch_all()

    # Merge daily if possible
    if not data["gilt"].empty:
        daily = data["gilt"].copy()
        for name, cols in [
            ("bund", ["bund_first", "bund_last", "bund_delta"]),
            ("gbp",  ["gbp_first", "gbp_last", "gbp_delta"]),
            ("ust",  ["ust_yield"]),
            ("vix",  ["VIX"]),
        ]:
            df = data[name]
            if not df.empty:
                daily = daily.merge(df, on="date", how="left")
        daily = daily.dropna().sort_values("date").reset_index(drop=True)
    else:
        print("⚠️  Skipping daily merge (no gilt data).")
        daily = pd.DataFrame()

    # Show samples
    for k, df in data.items():
        print(f"\n=== {k.upper()} ===")
        print(df.tail(5))
    print("\n=== DAILY MERGED ===")
    print(daily.tail(10))

    # Save
    with pd.ExcelWriter(OUT_XLSX, engine="xlsxwriter") as xw:
        for key, df in data.items():
            df.to_excel(xw, sheet_name=key[:31], index=False)
        if not daily.empty:
            daily.to_excel(xw, "daily", index=False)

    print(f"\nSaved: {OUT_XLSX}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n❌ Script failed: {e}")
        sys.exit(1)
