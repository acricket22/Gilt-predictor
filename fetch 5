"""
Bloomberg pull for gilt-open inputs (with GT10 Govt as UST yield)

- Intraday 5m (07:00–08:00 London): RX1, GBPUSD
- Daily: GT10 Govt (PX_LAST), VIX Index (PX_LAST), Gilt (PX_OPEN→PX_LAST)
- Saves results to bbg_gilt_inputs.xlsx
"""

import pandas as pd
import numpy as np
import pdblp
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
import pytz
import sys

# --------- CONFIG ---------
LONDON_TZ = pytz.timezone("Europe/London")

TICKERS = {
    "gilt_future": "G 1 Comdty",     # adjust if your desk uses another gilt chain
    "bund_future": "RX1 Comdty",
    "ust_yield":  "GT10 Govt",       # U.S. 10Y benchmark yield
    "gbpusd_spot": "GBPUSD Curncy",
    "vix_index":   "VIX Index",
}

PREOPEN_START = (7, 0)
PREOPEN_END   = (8, 0)
BAR_INTERVAL_MIN = 5

INTRADAY_LOOKBACK_DAYS = 90
DAILY_LOOKBACK_MONTHS  = 3
OUT_XLSX = "bbg_gilt_inputs.xlsx"
# --------------------------


def business_days_london(start_date, end_date):
    return pd.date_range(start=start_date, end=end_date, freq="B", tz=LONDON_TZ)


def safe_bdh(con, tickers, fields, start_date, end_date):
    """Safe bdh → tidy [date,ticker,field,value]; empty DF on error."""
    if isinstance(tickers, str): tickers = [tickers]
    if isinstance(fields, str):  fields  = [fields]
    try:
        df = con.bdh(tickers, fields, start_date, end_date)
        if df is None or df.empty:
            print(f"⚠️  safe_bdh: no data for tickers={tickers} fields={fields}")
            return pd.DataFrame(columns=["date","ticker","field","value"])
        df = df.stack(level=0).reset_index()
        df.columns = ["date","field","ticker","value"]
        return df
    except Exception as e:
        print(f"❌ safe_bdh error for tickers={tickers} fields={fields}: {e}")
        return pd.DataFrame(columns=["date","ticker","field","value"])


def normalize_bdib(bars: pd.DataFrame) -> pd.DataFrame:
    """Normalize bdib output across pdblp versions."""
    if bars is None or bars.empty:
        return pd.DataFrame()
    if isinstance(bars.index, pd.DatetimeIndex) and "time" not in bars.columns:
        bars = bars.reset_index()
    bars.columns = [str(c).lower() for c in bars.columns]
    if "time" not in bars.columns and "datetime" in bars.columns:
        bars = bars.rename(columns={"datetime": "time"})
    if "close" not in bars.columns and "price" in bars.columns:
        bars = bars.rename(columns={"price": "close"})
    if "close" not in bars.columns:
        raise ValueError("bdib: no close column found")
    if "time" not in bars.columns:
        raise ValueError("bdib: no time column found")
    return bars[["time", "close"]]


def get_intraday_first_last(con, ticker, dates, start_hm, end_hm, interval):
    """Pull 5m intraday bars (07:00–08:00) and compute first/last/delta."""
    rows = []
    for d in dates:
        d_loc = d.astimezone(LONDON_TZ)
        start_dt = d_loc.replace(hour=start_hm[0], minute=start_hm[1])
        end_dt   = d_loc.replace(hour=end_hm[0], minute=end_hm[1])
        start_naive = start_dt.replace(tzinfo=None)
        end_naive   = end_dt.replace(tzinfo=None)
        try:
            try:
                bars = con.bdib(ticker, start_naive, end_naive, eventType="TRADE", interval=interval)
            except TypeError:
                bars = con.bdib(ticker, start_naive, end_naive, "TRADE", interval)
            bars = normalize_bdib(bars)
        except Exception as e:
            print(f"❌ bdib error for {ticker} on {d_loc.date()}: {e}")
            continue
        if bars.empty:
            continue
        bars = bars.sort_values("time")
        first_px = float(bars["close"].iloc[0])
        last_px  = float(bars["close"].iloc[-1])
        rows.append({"date": d_loc.date(), "first": first_px, "last": last_px, "delta": last_px - first_px})
    return pd.DataFrame(rows)


def fetch_all():
    con = pdblp.BCon(host="localhost", port=8194, timeout=5000)
    con.start()

    today_loc = datetime.now(tz=LONDON_TZ).date()
    intraday_start = today_loc - timedelta(days=INTRADAY_LOOKBACK_DAYS)
    daily_start = (datetime.now(tz=LONDON_TZ) - relativedelta(months=DAILY_LOOKBACK_MONTHS)).date()
    days = business_days_london(intraday_start, today_loc)

    print("Pulling intraday Bund & GBPUSD (07:00–08:00 London)...")
    bund = get_intraday_first_last(con, TICKERS["bund_future"], days, PREOPEN_START, PREOPEN_END, BAR_INTERVAL_MIN)
    gbp  = get_intraday_first_last(con, TICKERS["gbpusd_spot"], days, PREOPEN_START, PREOPEN_END, BAR_INTERVAL_MIN)

    bund = bund.rename(columns={"first":"bund_first","last":"bund_last","delta":"bund_delta"})
    gbp  = gbp.rename(columns={"first":"gbp_first","last":"gbp_last","delta":"gbp_delta"})

    print("Pulling daily GT10 Govt (UST yield), VIX, and Gilt...")
    ust_bdh  = safe_bdh(con, TICKERS["ust_yield"],  "PX_LAST", daily_start, today_loc)
    vix_bdh  = safe_bdh(con, TICKERS["vix_index"],  "PX_LAST", daily_start, today_loc)
    gilt_bdh = safe_bdh(con, TICKERS["gilt_future"], "PX_OPEN", daily_start, today_loc)
    if gilt_bdh.empty:
        print("⚠️  Gilt PX_OPEN unavailable; falling back to PX_LAST")
        gilt_bdh = safe_bdh(con, TICKERS["gilt_future"], "PX_LAST", daily_start, today_loc)

    ust  = ust_bdh.loc[ust_bdh["field"] == "PX_LAST", ["date","value"]].rename(columns={"value":"ust_yield"})
    vix  = vix_bdh.loc[vix_bdh["field"] == "PX_LAST", ["date","value"]].rename(columns={"value":"VIX"})
    gilt = gilt_bdh.loc[:, ["date","value"]].rename(columns={"value":"gilt_open"})

    con.stop()
    return {"bund": bund, "gbp": gbp, "ust": ust, "vix": vix, "gilt": gilt}


def main():
    data = fetch_all()

    # Merge daily if possible
    if not data["gilt"].empty:
        daily = data["gilt"].copy()
        for name, cols in [("bund", ["bund_first","bund_last","bund_delta"]),
                           ("gbp",  ["gbp_first","gbp_last","gbp_delta"]),
                           ("ust",  ["ust_yield"]),
                           ("vix",  ["VIX"])]:
            df = data[name]
            if not df.empty:
                daily = daily.merge(df, on="date", how="left")
        daily = daily.dropna().sort_values("date").reset_index(drop=True)
    else:
        print("⚠️  Skipping daily merge (no gilt data).")
        daily = pd.DataFrame()

    # Show samples
    for k, df in data.items():
        print(f"\n=== {k.upper()} ===")
        print(df.tail(5))
    print("\n=== DAILY MERGED ===")
    print(daily.tail(10))

    # Save
    with pd.ExcelWriter(OUT_XLSX, engine="xlsxwriter") as xw:
        for key, df in data.items():
            df.to_excel(xw, sheet_name=key[:31], index=False)
        if not daily.empty:
            daily.to_excel(xw, "daily", index=False)

    print(f"\nSaved: {OUT_XLSX}")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\n❌ Script failed: {e}")
        sys.exit(1)
